<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"stellarkey.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"b2t":false,"scrollpercent":true,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"P1TCRNQBR7","apiKey":"501e087ded257acc9dc481944c14c248","indexName":"云端","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>


  <meta name="description" content="林伟在《人工智能的新数学》主题报告中，指出人工智能中经典的数学工具，有以下四类：  概率论、数理统计； 数值代数、数值分析、最优化； 经典分析、函数论（比如深度学习的逼近论相关知识）； 计算机科学基础，包括离散数学、理论计算机科学。  经典数学工具对于学生而言，是最应该掌握、最核心的工具。">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能中的“新”数学">
<meta property="og:url" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/index.html">
<meta property="og:site_name" content="思维之海">
<meta property="og:description" content="林伟在《人工智能的新数学》主题报告中，指出人工智能中经典的数学工具，有以下四类：  概率论、数理统计； 数值代数、数值分析、最优化； 经典分析、函数论（比如深度学习的逼近论相关知识）； 计算机科学基础，包括离散数学、理论计算机科学。  经典数学工具对于学生而言，是最应该掌握、最核心的工具。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222160231066.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222155504083.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/fec6278793691d25ee4a3edf89eff904.webp">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-16a0a97ac9453977c13d1ee527eca0c2_720w.jpg">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-04a7af5f35589b958b83e9e56ba5f124_720w.jpg">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222151629104.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222222935682.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222225431590.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/1549049058360.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/1549049282169.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/1549049512585.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/175px-Natural_transformation.svg.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222201729074.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222202014577.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-6ad7768d4f98dfe0b9739ba9f0bf3390_720w.jpg">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222215836927.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222202401528.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222202947031.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/ResNetUnit.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-7cb9c03871ab1faa7ca23199ac403bd9_720w.jpg">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-00f2369204775ba6f2dd1f3741f539eb_r.jpg">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222215911981.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222215946268.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222220023514.png">
<meta property="og:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222220046838.png">
<meta property="article:published_time" content="2020-12-17T06:00:51.000Z">
<meta property="article:modified_time" content="2021-01-04T16:28:26.211Z">
<meta property="article:author" content="工云">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222160231066.png">

<link rel="canonical" href="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>人工智能中的“新”数学 | 思维之海</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="思维之海" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">思维之海</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">——在云端，寻找我的星匙。</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fas fa-anchor fa-fw"></i> </a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fas fa-th fa-fw"></i> </a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fas fa-tags fa-fw"></i> </a>

  </li>
        <li class="menu-item menu-item-link">

    <a href="/link/" rel="section"><i class="fas fa-link fa-fw"></i> </a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fas fa-user fa-fw"></i> </a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

    
    

    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/stellarkey.gif">
      <meta itemprop="name" content="工云">
      <meta itemprop="description" content="Never stop thinking.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="思维之海">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          人工智能中的“新”数学
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Learn/" itemprop="url" rel="index"><span itemprop="name">Learn</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a href="https://www.stat-center.pku.edu.cn/zxry/zxjy/lw/1227407.htm" target="_blank" rel="noopener external nofollow noreferrer">林伟</a>在《人工智能的新数学》主题报告中，指出人工智能中经典的数学工具，有以下四类：</p>
<ul>
<li>概率论、数理统计；</li>
<li>数值代数、数值分析、最优化；</li>
<li>经典分析、函数论（比如深度学习的逼近论相关知识）；</li>
<li>计算机科学基础，包括离散数学、理论计算机科学。</li>
</ul>
<p>经典数学工具对于学生而言，是最应该掌握、最核心的工具。</p>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222160231066.png" class="" title="人工智能中的“旧”数学">
<a id="more"></a>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><a href="https://mp.weixin.qq.com/s/ElJN4nK3ByQ2ulxgq4qJvw" target="_blank" rel="noopener external nofollow noreferrer">AI的十种”新数学“</a></p>
<iframe src="//player.bilibili.com/player.html?aid=927809167&bvid=BV1dK4y1Z7uQ&cid=257459123&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p><a href="https://www.bilibili.com/video/BV1954y1r7UU" target="_blank" rel="noopener external nofollow noreferrer">林宙辰-下一代机器学习</a></p>
<blockquote>
<p>这里面也提到了人脑的系统1和系统2（系统1 / Intuitive 是现在的深度学习，系统2 / Logical 是未来的研究方向）。</p>
</blockquote>
<p><a href="https://www.zhihu.com/column/eleven-dimension-math" target="_blank" rel="noopener external nofollow noreferrer">Meet in Maths</a></p>
<h1 id="泛函分析"><a href="#泛函分析" class="headerlink" title="泛函分析"></a>泛函分析</h1><p><a href="https://vel.life/%E6%B3%9B%E5%87%BD%E5%88%86%E6%9E%90/" target="_blank" rel="noopener external nofollow noreferrer">泛函分析</a></p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/50118911" target="_blank" rel="noopener external nofollow noreferrer">从度量空间、线性空间到希尔伯特空间- 知乎</a></p>
<p><a href="https://jishuin.proginn.com/p/763bfbd31a95" target="_blank" rel="noopener external nofollow noreferrer">度量、范数和内积原来是这么个关系</a></p>
<p><a href="http://www.fanyeong.com/2017/11/13/the-kernel-trick/" target="_blank" rel="noopener external nofollow noreferrer">核技巧（The Kernel Trick） | 范永勇</a></p>
</blockquote>
<h2 id="巴拿赫空间"><a href="#巴拿赫空间" class="headerlink" title="巴拿赫空间"></a>巴拿赫空间</h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/113197869" target="_blank" rel="noopener external nofollow noreferrer">希尔伯特空间</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222155504083.png" class="" title="巴拿赫空间">
<p><strong><font color=red>度量</font></strong>：$X$是一个集合，度量是$X$上的一个<strong>二元关系</strong>（$X \times X \rightarrow R$），对于任意的 $x, y, z \in X$：</p>
<ul>
<li>非负：$\rho(x, y) \geq 0$，（非退化）当且仅当 $x=y$ 时等号成立</li>
<li>对称：$\rho(x, y)=\rho(y, x)$</li>
<li>三角不等式：$\rho(x, z) \leq \rho(x, y)+\rho(y, z)$ 。</li>
</ul>
<p><strong><font color=red>范数</font></strong>：范数是一种线性空间上的度量，它还满足</p>
<ul>
<li>齐次：对于所有 $\mathbf{v} \in V$ 和 $\lambda \in \mathbb{R},$ 有 $|\lambda \mathbf{v}|=|\lambda| \cdot | \mathbf{v} |$</li>
</ul>
<p><strong><font color=red>内积</font></strong>：内积是一种线性空间上的范数，它还满足</p>
<ul>
<li>分配律：对于所有向量 $\mathbf{u}, \mathbf{v}, \mathbf{w} \in V,$ 都有 $\langle\mathbf{v}, \mathbf{w}+\mathbf{u})=\langle\mathbf{v}, \mathbf{w}\rangle+\langle\mathbf{v}, \mathbf{u}\rangle$</li>
</ul>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/fec6278793691d25ee4a3edf89eff904.webp" class="" title="度量空间，赋范空间，内积空间">
<blockquote>
<p><strong><font color=blue>核技巧</font></strong>（Kernel Trick）就是一种内积。</p>
<script type="math/tex; mode=display">
K(x, y)=\langle\phi(x), \phi(y)\rangle</script><p>其中，$\phi(x)$是指将样本向量 $x$ <strong>从输入空间映射到特征空间</strong>（希尔伯特空间），从而在高维线性可分。因为我们不需要知道$\phi(x)$的具体形式，所以可以直接通过定义核函数$K(x,y)$的方式获得$\phi(x)$的隐式定义。</p>
<p>Q: 那么如何确定 $\phi(x)$ 映射到一个高维空间呢？</p>
<blockquote>
<p>A: 这部分需要查阅核函数的理论推导。</p>
<p>比如，</p>
<ul>
<li>线性核，其实就是没有映射<ul>
<li>$\kappa\left(x<em>{1}, x</em>{2}\right)=\langle x 1, x 2\rangle$</li>
</ul>
</li>
<li><strong><font color=red>高斯核</font></strong>函数，也称径向基(RBF)函数，使用最为广泛，<strong>它能够把原始特征映射到<font color=red>无穷维</font></strong><ul>
<li>$\kappa\left(x<em>{1}, x</em>{2}\right)= \exp \left(-\gamma\left|\mathbf{x}<em>{1}-\mathbf{x}</em>{2}\right|_{2}^{2}\right)$</li>
</ul>
</li>
<li>多项式核函数，它能把数据映射到$C_{n+d}^{n}$维<ul>
<li>$\kappa\left(x<em>{1}, x</em>{2}\right)=\left(\left\langle x<em>{1}, x</em>{2}\right\rangle+R\right)^{d}$</li>
</ul>
</li>
</ul>
</blockquote>
</blockquote>
<p><strong><font color=red>完备</font></strong>：一个完备空间中的任何<a href="https://zh.wikipedia.org/wiki/柯西序列" target="_blank" rel="noopener external nofollow noreferrer">柯西序列</a>都收敛在该空间之内。</p>
<h2 id="从函数到无穷维"><a href="#从函数到无穷维" class="headerlink" title="从函数到无穷维"></a>从函数到无穷维</h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/135898326" target="_blank" rel="noopener external nofollow noreferrer"><strong>RBF 核函数背后隐藏着怎样的映射？</strong></a></p>
<p><a href="https://www.zhihu.com/question/39890018" target="_blank" rel="noopener external nofollow noreferrer">如何理解「函数可以看成是一个无限维的向量」？</a></p>
<p><a href="http://www.360doc.com/content/19/1110/15/39821762_872262517.shtml" target="_blank" rel="noopener external nofollow noreferrer">重新理解函数空间（上）</a></p>
<p><a href="https://charlesliuyx.github.io/2018/02/18/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E8%AE%A9%E4%BD%A0%E6%B0%B8%E8%BF%9C%E5%BF%98%E4%B8%8D%E4%BA%86%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A7%A3%E6%9E%90/" target="_blank" rel="noopener external nofollow noreferrer">【直观详解】让你永远忘不了的傅里叶变换解析</a> Fourier 变换是将时域信号转换为频域信号，Fourier 解析是将频域信号转换为时域信号。</p>
</blockquote>
<h3 id="脉冲"><a href="#脉冲" class="headerlink" title="*脉冲"></a>*脉冲</h3><blockquote>
<p><a href="https://vel.life/%E7%AE%97%E6%B3%95-%E6%91%8A%E8%BF%98%E5%88%86%E6%9E%90%EF%BC%9A%E4%BB%B7%E6%A0%BC%E6%82%96%E8%AE%BA/" target="_blank" rel="noopener external nofollow noreferrer">摊还分析：价格悖论</a></p>
</blockquote>
<p><strong><font color=red>脉冲函数</font></strong>：<a href="https://zh.wikipedia.org/wiki/%E7%8B%84%E6%8B%89%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0" target="_blank" rel="noopener external nofollow noreferrer">Dirac函数</a>。</p>
<hr>
<h3 id="高斯核背后的映射"><a href="#高斯核背后的映射" class="headerlink" title="高斯核背后的映射"></a>高斯核背后的映射</h3><p>不妨设在一维空间。如图，两个样本点：</p>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-16a0a97ac9453977c13d1ee527eca0c2_720w.jpg" class="" title="两个样本点">
<p>将点映射成一个函数 / 分布：（类傅里叶解析）</p>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-04a7af5f35589b958b83e9e56ba5f124_720w.jpg" class="" title="函数">
<p>此时，函数空间构成了一个无穷维空间。</p>
<blockquote>
<p>可以想象一个<strong>无限细分的柱形图</strong>，每一根立柱就是一个维度。</p>
</blockquote>
<p>比如，将样本${\color{red}{x_1} },{\color{blue}{x_2} }$映射为两个高斯分布，</p>
<script type="math/tex; mode=display">
\begin{equation}
f_{1}(x)=\exp \left[-\frac{\left(x-{\color{red}{x_{1} } }\right)^{2}}{2 \sigma^{2}}\right], \quad f_{2}(x)=\exp \left[-\frac{\left(x-{\color{blue}{x_{2} } }\right)^{2}}{2 \sigma^{2}}\right]
\end{equation}</script><p>定义函数内积为相乘后的积分：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
K\left(x_{1}, x_{2}\right) &=\left\langle\phi\left(x_{1}\right), \phi\left(x_{2}\right)\right\rangle=\left\langle f_{1}, f_{2}\right\rangle \\
&=\int_{\infty}^{+\infty} f_{1}(x) f_{2}(x) \mathrm{d} x \\
&=\int_{-\infty}^{+\infty} \exp \left[-\frac{\left(x-x_{1}\right)^{2}}{2 \sigma^{2}}\right] \cdot \exp \left[-\frac{\left(x-x_{2}\right)^{2}}{2 \sigma^{2}}\right] \mathrm{d} x \\
&=\int_{\infty}^{+\infty} \exp \left[-\frac{2 x^{2}-2\left(x_{1}+x_{2}\right) x+\left(x_{1}^{2}+x_{2}^{2}\right)}{2 \sigma^{2}}\right] \mathrm{d} x \\
&=\int_{\infty}^{+\infty} \exp \left\{-\frac{1}{\sigma^{2}}\left[\left(x-\frac{x_{1}+x_{2}}{2}\right)^{2}+\left(\frac{x_{1}-x_{2}}{2}\right)^{2}\right]\right\} \mathrm{d} x \\
&={\color{red}{\int_{-\infty}^{+\infty} \exp \left(-\frac{x^{2}}{\sigma^{2}}\right) \mathrm{d} x} } \cdot \exp \left[-\frac{\left(x_{1}-x_{2}\right)^{2}}{4 \sigma^{2}}\right] \\
&=\sqrt{\pi} \sigma \cdot \exp \left[\frac{\left(x_{1}-x_{2}\right)^{2}}{4 \sigma^{2}}\right]
\end{aligned}
\end{equation}</script><p>忽略掉系数，就得到了一个高斯核。</p>
<h2 id="无穷宽的DNN"><a href="#无穷宽的DNN" class="headerlink" title="无穷宽的DNN"></a>无穷宽的DNN</h2><blockquote>
<p><a href="https://arxiv.org/abs/2007.15623" target="_blank" rel="noopener external nofollow noreferrer">On the Banach spaces associated with multi-layer ReLU networks: Function representation, approximation theory and gradient descent dynamics</a></p>
<blockquote>
<p><strong>We develop Banach spaces for ReLU neural networks of finite depth L and infinite width</strong>. The spaces contain all finite fully connected L-layer networks and their L2-limiting objects under bounds on the natural path-norm. Under this norm, the…</p>
</blockquote>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222151629104.png" class="" title="无穷宽网络">
<p>因为宽度无穷宽，就构成了一个无穷维的巴纳赫空间（完备的赋范线性空间）。</p>
<h1 id="群表示论与范畴论"><a href="#群表示论与范畴论" class="headerlink" title="群表示论与范畴论"></a>群表示论与范畴论</h1><p><a href="https://vel.life/抽象代数基础/" target="_blank" rel="noopener external nofollow noreferrer">抽象代数基础</a></p>
<p><a href="https://vel.life/%E7%BE%A4%E8%A1%A8%E7%A4%BA%E8%AE%BA/" target="_blank" rel="noopener external nofollow noreferrer">群表示论</a></p>
<p><a href="https://vel.life/%E8%8C%83%E7%95%B4%E8%AE%BA/" target="_blank" rel="noopener external nofollow noreferrer">范畴论</a></p>
<blockquote>
<p><a href="https://www.math.arizona.edu/~xuehang/rep_notes.pdf" target="_blank" rel="noopener external nofollow noreferrer">中国科学院暑假学校讲义: 群表示论的一些小知识</a></p>
</blockquote>
<h2 id="关于群的研究"><a href="#关于群的研究" class="headerlink" title="关于群的研究"></a>关于群的研究</h2><blockquote>
<p><a href="https://mp.weixin.qq.com/s/-bxH9Sp9_p2sK8VlAxZslQ" target="_blank" rel="noopener external nofollow noreferrer">一个半世纪的征程—有限单群分类定理（上）</a></p>
<p><a href="https://mp.weixin.qq.com/s/hErfHxgNO9Zjk_XlBus7Tw" target="_blank" rel="noopener external nofollow noreferrer">24维晶体中特有的对称—-有限单群分类定理（中）</a></p>
<p><a href="https://mp.weixin.qq.com/s/JtAZmfKHrsmf6lUtM48VgQ" target="_blank" rel="noopener external nofollow noreferrer">月光下的群魔—有限单群分类定理（下）</a></p>
<p><a href="https://fwjmath.wordpress.com/2011/09/15/finite-simple-group-history/" target="_blank" rel="noopener external nofollow noreferrer">有限单群：一段百年征程</a></p>
</blockquote>
<p>一个群就是一个代数系统。</p>
<p>现代数学研究群的结构一般有两种方法：</p>
<ul>
<li><strong><font color=blue>研究子群</font></strong><ul>
<li>3b1b视频：<a href="https://www.bilibili.com/video/BV1Rh411R7KL" target="_blank" rel="noopener external nofollow noreferrer">群论与 808017424794512875886459904961710757005754368000000000</a></li>
<li>对有限群的基本群即单群（Simple groups）进行分类<ul>
<li>有限群就是有限个元素构成的群</li>
<li>2004年由一篇100多位数学家写成的1200多页的Paper收尾<ul>
<li>$\Longrightarrow$ 有限单群分类定理</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222222935682.png" class="" title="单群的分类">
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222225431590.png" class="" title="有限单群周期表 - 大老李谈数学">
<ul>
<li><strong><font color=blue>研究群的表示</font></strong><ul>
<li>群的表示就是把给定的群$G$同态地映到另一个群$W$的操作（同态就是<strong>保持运算</strong>）。<ul>
<li>通过不同的表示，我们可以通过各种熟悉的$W$，来从不同的角度观察$G$的性质，从而认识未知的事物</li>
<li>什么样的群表示最值得研究？<ul>
<li>不可约表示：一个表示被称作不可约的，当且仅当它没有在G的作用下不变的非平凡子空间。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>同态映射反映了两个代数系统的<strong>被映射部分</strong>的局部相似性（即同种规律在不同体系下的表示）。</p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/1549049058360.png" class="" title="同态映射">
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/1549049282169.png" class="" title="同态满射">
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/1549049512585.png" class="" title="同构映射">
<h2 id="从图到范畴论"><a href="#从图到范畴论" class="headerlink" title="从图到范畴论"></a>从图到范畴论</h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/108528537" target="_blank" rel="noopener external nofollow noreferrer">范畴论简史- 知乎</a></p>
<p><a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AE%8A%E6%8F%9B" target="_blank" rel="noopener external nofollow noreferrer">自然变换</a></p>
</blockquote>
<p>范畴论使用图论作为描述工具，节点表示一个<strong>对象</strong>，有向边表示<strong>态射</strong>，整个图构成一个<strong>范畴</strong>。</p>
<blockquote>
<p>范畴，就是具有代数结构的有向图。</p>
</blockquote>
<p>范畴论是“数学的数学”，它试图研究各种数学结构之间的联系和共性。</p>
<p><strong><font color=red>函子</font></strong>（Functor）：如果范畴本身也作为一个对象，那么就可以创造更高阶的范畴，在这样的高阶范畴中的态射称为函子。</p>
<p><strong><font color=red>自然变换</font></strong>：把函子也作为一个对象，函子和函子间的态射就称为自然变换。</p>
<blockquote>
<p>设C和D是范畴，F和G是C和D之间的函子。一个从F到G 的自然变换η，对C中每个对象，给出一个在D的对象间的态射ηX : F(X) → G(X)，称为η在X处的分量（component），使得对C中每个态射f : X → Y都有：</p>
</blockquote>
<script type="math/tex; mode=display">
\eta_{Y} \circ F(f)=G(f) \circ \eta_{X}</script><img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/175px-Natural_transformation.svg.png" class="" title="自然变换示例">
<h2 id="DNN中的对称性、函子"><a href="#DNN中的对称性、函子" class="headerlink" title="DNN中的对称性、函子"></a>DNN中的对称性、函子</h2><blockquote>
<p><a href="https://arxiv.org/abs/2008.01805" target="_blank" rel="noopener external nofollow noreferrer">Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale of Symmetry</a></p>
<p><a href="https://arxiv.org/abs/1711.10455" target="_blank" rel="noopener external nofollow noreferrer">Backprop as Functor: A compositional perspective on supervised learning</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222201729074.png" class="" title="群表示论与范畴论示例">
<p>神经网络中存在一些冗余，这些冗余可以利用群表示论的技术进行一些修剪。</p>
<p>函子（Functor）适合于用来表达函数的复合。</p>
<h1 id="微分几何"><a href="#微分几何" class="headerlink" title="微分几何"></a>微分几何</h1><blockquote>
<p><a href="https://link.springer.com/chapter/10.1007/978-3-642-00826-9_4" target="_blank" rel="noopener external nofollow noreferrer">Information Geometry and Its Applications: Convex Function and Dually Flat Manifold</a></p>
<p><a href="https://www.bilibili.com/video/BV1Lb411g7nL" target="_blank" rel="noopener external nofollow noreferrer">A Thorough Introduction to The Theory of General Relativity</a> 前12节课</p>
<p><a href="https://link.springer.com/book/10.1007/978-3-319-96992-3" target="_blank" rel="noopener external nofollow noreferrer">A Visual Introduction to Differential Forms and Calculus on Manifolds</a></p>
</blockquote>
<h2 id="微分流形"><a href="#微分流形" class="headerlink" title="微分流形"></a>微分流形</h2><p><strong><font color=red>流形</font></strong>（Manifold）：可以局部欧几里得空间化的一个拓扑空间。</p>
<blockquote>
<p>希尔伯特空间就是欧几里得空间推广到无穷维。</p>
<p>比如，李群是一个在拓扑群上加上了微分结构的代数结构，让拓扑群的拓扑空间成为<a href="https://zh.wikipedia.org/wiki/%E5%BE%AE%E5%88%86%E6%B5%81%E5%BD%A2" target="_blank" rel="noopener external nofollow noreferrer">微分流形</a>。</p>
<p>李群既是群也是流形。</p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/51199404" target="_blank" rel="noopener external nofollow noreferrer">MP67：典型群(1)：拓扑性质</a></p>
</blockquote>
</blockquote>
<p>可微流形上的微积分研究被称为<strong>微分几何</strong>，利用微积分理论研究空间的几何性质。</p>
<h2 id="深度学习的几何解释"><a href="#深度学习的几何解释" class="headerlink" title="深度学习的几何解释"></a>深度学习的几何解释</h2><blockquote>
<p><a href="https://arxiv.org/abs/1805.10451" target="_blank" rel="noopener external nofollow noreferrer">Geometric Understanding of Deep Learning</a> 顾险峰团队</p>
<p><a href="https://arxiv.org/abs/1710.05488" target="_blank" rel="noopener external nofollow noreferrer">A Geometric View of Optimal Transportation and Generative Model</a></p>
</blockquote>
<p><strong><font color=red>流形分布律</font></strong>：不同的类对应着流形上的不同概率分布，这些分布之间的距离大到足够将这些类区分。 </p>
<blockquote>
<p>顾险峰在公众号文章《<a href="https://mp.weixin.qq.com/s/v9kXLFp_lZziT4er9n2HFQ" target="_blank" rel="noopener external nofollow noreferrer">基本工程问题是否需要前沿几何理论？</a>》中提到：</p>
<blockquote>
<p>大数据的本质模式可以概括为如下的物理定则（Physics law）：</p>
<ul>
<li><strong><font  color=blue>一类自然数据可以被视作嵌入在高维空间中的低维流形上的概率分布</font>。</strong></li>
</ul>
<p>深度学习具有两个主要任务：</p>
<ul>
<li>一是<strong>学习流形结构</strong>，表示为编码和解码映射，流形的参数空间就是隐空间或者特征空间；</li>
<li>二是<strong>概率分布变换</strong>，即将白噪声变换成数据分布。</li>
</ul>
<p>深度神经网络的唯一功能就是表达欧式空间之间的连续映射，因此在统计深度学习领域，所有的数据都被表示成映射，概率分布也被表示成映射，即从白噪声到给定概率分布间的传输变换（transportation map）。由此，<strong>统计深度学习可以由范畴语言来表述</strong>，其范畴为{流形上的概率分布，流形间的映射}。</p>
</blockquote>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222202014577.png" class="" title="微分几何示例">
<p>利用流形上的数学来研究GAN中从输入到输出之间的一些关系。</p>
<h1 id="计算共形几何与最优传输"><a href="#计算共形几何与最优传输" class="headerlink" title="计算共形几何与最优传输"></a>计算共形几何与最优传输</h1><p><a href="https://vel.life/%E8%AE%A1%E7%AE%97%E5%85%B1%E5%BD%A2%E5%87%A0%E4%BD%95/" target="_blank" rel="noopener external nofollow noreferrer">计算共形几何</a></p>
<blockquote>
<p><a href="https://www.jiqizhixin.com/articles/2018-11-09-5" target="_blank" rel="noopener external nofollow noreferrer">WGAN-div：默默无闻的WGAN填坑者| 附开源代码| 机器之心</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/58506295" target="_blank" rel="noopener external nofollow noreferrer">Wasserstein Distance 讲解</a></p>
</blockquote>
<h2 id="最优传输散度"><a href="#最优传输散度" class="headerlink" title="最优传输散度"></a>最优传输散度</h2><p><strong><font color=red>最优传输</font></strong>的问题便是，有两个概率分布，怎样从一个概率分布迁移到另外一个概率分布？所以它也叫“推土机”，类似推土机一样把分布以最小的代价变成另外一个概率分布；目标是要解一个问题，每一点移动有一个代价，要使得这个移动总代价是最低的。</p>
<p>最优传输可以用来描述两个概率分布之间的距离，称为<strong>最优传输散度</strong>，即：<a href="https://zhuanlan.zhihu.com/p/58506295" target="_blank" rel="noopener external nofollow noreferrer"><strong>Wasserstein Distance</strong></a>。跟统计学中KL散度的作用类似；但是，KL散度有一些缺陷：没有对称性，无法衡量离散分布和连续分布的距离……</p>
<script type="math/tex; mode=display">
\begin{equation}
W_{p}(\mu, \nu)=\left(\inf _{\gamma \in \Gamma(\mu, \nu)} \int_{\mathcal{X} \times \mathcal{X}}\|x-y\|^{p} d \gamma(x, y)\right)^{1 / p}
\end{equation}</script><img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-6ad7768d4f98dfe0b9739ba9f0bf3390_720w.jpg" class="" title="最优传输示例 - 知乎@张楚珩">
<h2 id="GAN的模式崩溃"><a href="#GAN的模式崩溃" class="headerlink" title="GAN的模式崩溃"></a>GAN的模式崩溃</h2><blockquote>
<p><a href="https://arxiv.org/abs/1803.00567" target="_blank" rel="noopener external nofollow noreferrer">Computational Optimal Transport</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222215836927.png" class="" title="最优传输示例">
<hr>
<p>最优传输特别适合用来描述对抗生成网络（GAN）里面的问题。</p>
<blockquote>
<p>这部分研究也是顾险峰团队在推动。</p>
</blockquote>
<p>GAN的训练中有一种被称为<strong><font color=blue>模式崩溃</font></strong>（Mode Collapsing）的现象。GNN在学习多模态（mode）的分布时，经常只能收敛到其中的部分模态。即使经过正则一类的措施能够让GAN覆盖所有模态，却会生成虚假的样本。</p>
<p>顾险峰团队认为，其中的本质原因是，<strong>深度神经网络只能表示连续映射，而最优传输映射整体是非连续的</strong>。</p>
<h1 id="代数几何"><a href="#代数几何" class="headerlink" title="代数几何"></a>代数几何</h1><p>代数几何的基本研究对象是在任意维数的（仿射或射影）空间中，由若干个代数方程的公共零点所构成的集合的几何特性。</p>
<h2 id="热带几何"><a href="#热带几何" class="headerlink" title="热带几何"></a>热带几何</h2><blockquote>
<p><a href="https://arxiv.org/abs/1805.07091" target="_blank" rel="noopener external nofollow noreferrer">Tropical Geometry of Deep Neural Networks</a></p>
</blockquote>
<p>热带几何是<strong>分片线性化</strong>的代数几何。</p>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222202401528.png" class="" title="热带几何">
<p>因为ReLU函数是{X,0}取大，通过这个取大操作以及加法、减法，定义了一些热带几何上的运算，通过这几种预算，我们就可以定义一种多项式。多项式就涉及到了代数几何的研究范畴。</p>
<h1 id="计算机代数"><a href="#计算机代数" class="headerlink" title="计算机代数"></a>计算机代数</h1><p><a href="https://vel.life/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BB%A3%E6%95%B0/" target="_blank" rel="noopener external nofollow noreferrer">计算机代数</a></p>
<blockquote>
<p><a href="https://vel.life/第二届AI与安全研讨会/" target="_blank" rel="noopener external nofollow noreferrer">第二届 AI 与安全研讨会</a></p>
</blockquote>
<h2 id="向量空间、符号空间"><a href="#向量空间、符号空间" class="headerlink" title="向量空间、符号空间"></a>向量空间、符号空间</h2><p>在第三代人工智能模型中，指出两天发展人工智能的道路：</p>
<ul>
<li>继续研究<strong><font color=deepskyblue>向量空间</font></strong><ul>
<li>最大挑战：<strong>语义丢失问题</strong></li>
</ul>
</li>
<li>走回知识驱动 + 数据驱动 $\longrightarrow$ <strong><font color=deepskyblue>符号空间</font></strong><ul>
<li><strong>在符号空间中，数学工具有限</strong><ul>
<li>朱军：符号空间的数学工具，将来大家将学习离散数学（<strong>数理逻辑</strong>），CS的还要学<strong>形式语言与自动机</strong>，<strong>组合数学</strong>，<strong>图论</strong>等相关课程，<strong>抽象代数</strong>（群、环、域）也相关</li>
</ul>
</li>
<li>缺少知识</li>
</ul>
</li>
</ul>
<h2 id="多项式代数"><a href="#多项式代数" class="headerlink" title="多项式代数"></a>多项式代数</h2><p>计算机代数主要指多项式代数，它实现了无精度损失的<strong>符号计算</strong>。属于符号空间中的数学工具。</p>
<p>计算机代数中常用的方法有<strong>Groebner基</strong>，<strong>三角列</strong>和<strong>柱形代数分解</strong>。</p>
<p>机器证明的底层数学工具就是计算机代数。</p>
<h1 id="随机矩阵"><a href="#随机矩阵" class="headerlink" title="随机矩阵"></a>随机矩阵</h1><blockquote>
<p><a href="https://arxiv.org/abs/1702.05419" target="_blank" rel="noopener external nofollow noreferrer">A Random Matrix Approach to Neural Networks</a></p>
<p><a href="https://papers.nips.cc/paper/6857-nonlinear-random-matrix-theory-for-deep-learning.pdf" target="_blank" rel="noopener external nofollow noreferrer">Nonlinear random matrix theory for deep learning - NIPS</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/37591888" target="_blank" rel="noopener external nofollow noreferrer">随机矩阵理论(RMT)综述</a></p>
</blockquote>
<p><strong><font color=red>随机矩阵</font></strong>：一个矩阵中的所有元素都是随机变量。</p>
<p><strong><font color=red>经验谱分布函数</font></strong>（ESD）：设 $\mathrm{A}$ 是一个具有 $n$ 个实特征根的 $n$ 阶方阵，记其特征根为 $\lambda<em>{1}, \cdots, \lambda</em>{n}$。这些特征根的分布可以用以下函数$F_n(x)$表示，称为方阵 $\mathrm{A}$ 的经验分布函数。（$I$ 为指示函数）</p>
<script type="math/tex; mode=display">
\begin{equation}
F_{n}(x)=\frac{1}{n} \sum_{k=1}^{n} I\left(\lambda_{k} \leqslant x\right)
\end{equation}</script><img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222202947031.png" class="" title="随机矩阵示例">
<p>大型神经网络的权值在某些情况下接近于随机分布。可以利用随机矩阵理论来刻画它的谱分布的一些性质。</p>
<h1 id="动力系统与随机分析"><a href="#动力系统与随机分析" class="headerlink" title="动力系统与随机分析"></a>动力系统与随机分析</h1><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/31852747" target="_blank" rel="noopener external nofollow noreferrer">你必须要知道CNN模型：ResNet</a></p>
</blockquote>
<p>ResNet的作者何凯明因为ResNet工作摘得CVPR2016最佳论文奖。</p>
<p>深度神经网络在加深层数时，除了过拟合、梯度消亡、爆炸的问题以外，还会遇到退化的问题（Degradation problem）。</p>
<p><strong><font color=red>残差学习</font></strong>（Residual learning）：定义学习到的特征为$H(x)$，而残差为$F(x)=H(x)-x$。现在神经网络学习$F(x)$ instead of $H(x)$。</p>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/ResNetUnit.png" class="" title="ResNet单元">
<blockquote>
<p>通过引入短路机制，残差网络的内部结构只需学习残差。当残差为0时，变为恒等映射。</p>
<p>因为残差的数量级较小，映射对于残差微小的变化较为敏感。</p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-7cb9c03871ab1faa7ca23199ac403bd9_720w.jpg" class="" title="ResNet网络结构图">
<h2 id="相平面图"><a href="#相平面图" class="headerlink" title="相平面图"></a>相平面图</h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/119390532" target="_blank" rel="noopener external nofollow noreferrer">非线性控制（二）相平面法</a></p>
</blockquote>
<p>相平面法是一种基于时域的分析方法。表示有两个独立变量的系统（二阶系统）的轨迹。</p>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/v2-00f2369204775ba6f2dd1f3741f539eb_r.jpg" class="" title="相平面图示例">
<h2 id="郎之万动力学"><a href="#郎之万动力学" class="headerlink" title="郎之万动力学"></a>郎之万动力学</h2><p>朗之万动力学 ( Langevin Dynamics ) 是控制模拟系统能量的一种常用算法。</p>
<p>在模拟一个大型系统时，误差会逐渐积累，朗之万动力学的实现方法是在系统中加入<strong>耗散力</strong>和<strong>随机力</strong>（相当于引入布朗运动），弱化系统误差，使得系统保持一定的平衡状态。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><blockquote>
<p><a href="https://arxiv.org/abs/1705.03341" target="_blank" rel="noopener external nofollow noreferrer">Stable Architectures for Deep Neural Networks</a></p>
<p><a href="https://arxiv.org/abs/1702.03849" target="_blank" rel="noopener external nofollow noreferrer">Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222215911981.png" class="" title="动力系统示例">
<p>动力系统主要是指稳定性的内容。<a href="https://arxiv.org/abs/1705.03341" target="_blank" rel="noopener external nofollow noreferrer">Stable Architectures for Deep Neural Networks</a>这篇文章是用相平面图来研究ResNet里面动力学的稳定性。</p>
<p>随机动力系统。比如：随机梯度下降。如果把它<strong>加一个人为的噪声</strong>（$\eta<em>{t} \sim N\left(0, \epsilon</em>{t}\right)$），变成带噪声的迭代，叫“<strong>随机梯度郎之万动力学</strong>”，会带来一些更好的表现。</p>
<h1 id="统计物理与非线性科学"><a href="#统计物理与非线性科学" class="headerlink" title="统计物理与非线性科学"></a>统计物理与非线性科学</h1><h2 id="平均场方法"><a href="#平均场方法" class="headerlink" title="平均场方法"></a>平均场方法</h2><p>平均场论（Mean field theory）是一种研究<strong>复杂多体问题</strong>的方法，将数量巨大的互相作用的多体问题转化成每一个粒子处在一种弱周期场中的单体问题。以<strong>平均作用效果</strong>替代单个作用效果的加和。</p>
<h2 id="混沌和分形"><a href="#混沌和分形" class="headerlink" title="混沌和分形"></a>混沌和分形</h2><blockquote>
<p><a href="http://www.global-sci.org/v1/mc/issues/3/no3/freepdf/35s.pdf" target="_blank" rel="noopener external nofollow noreferrer">自然的奥秘：混沌与分形</a></p>
<p><em>混沌是时间上的分形，分形是空间上的混沌。</em></p>
</blockquote>
<p>混沌和分形都是动力系统中非线性方程所描述的非平衡的过程和结果。</p>
<h2 id="一些相关工作"><a href="#一些相关工作" class="headerlink" title="一些相关工作"></a>一些相关工作</h2><blockquote>
<p><a href="https://arxiv.org/abs/1804.06561" target="_blank" rel="noopener external nofollow noreferrer">A Mean Field View of the Landscape of Two-Layers Neural Networks</a></p>
<p><a href="https://arxiv.org/abs/2006.09313" target="_blank" rel="noopener external nofollow noreferrer">Hausdorff Dimension, Stochastic Differential Equations, and Generalization in Neural Networks</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222215946268.png" class="" title="统计物理示例">
<p>最近有这样一个工作，两层神经网络可以做一个平均场近似，平均场方法几乎是物理学家的法宝，任何情况下都可以做一个平均场近似，大部分情况下都 work 得比较好。对于<strong>两层<font color=red>无穷宽</font>的神经网络</strong>，我们可以平均掉一些效果，这就可以得到一个比较好的跟实际效果吻合的预测。</p>
<p>非线性研究里还有很多研究混沌、分形几何之类的。举例来说，上图第二项工作是用随机梯度下降训练的轨道的分形维数来控制复杂度，由此可以得到一些泛化。</p>
<h1 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h1><p><a href="https://vel.life/%E4%BF%A1%E6%81%AF%E8%AE%BA/" target="_blank" rel="noopener external nofollow noreferrer">信息论</a></p>
<h2 id="信息瓶颈方法"><a href="#信息瓶颈方法" class="headerlink" title="信息瓶颈方法"></a>信息瓶颈方法</h2><blockquote>
<p><a href="https://www.zhihu.com/question/53245133" target="_blank" rel="noopener external nofollow noreferrer">如何解释通俗的解释信息瓶颈方法？</a></p>
<p><a href="https://wiki.mbalib.com/zh-tw/信息瓶颈" target="_blank" rel="noopener external nofollow noreferrer">信息瓶颈- MBA智库百科</a></p>
<p><a href="https://www.jiqizhixin.com/dailies/d6d8962c-18bc-446a-8c7b-c96b824afadc" target="_blank" rel="noopener external nofollow noreferrer">使用深度变分信息瓶颈方法解释黑盒子| 机器之心</a></p>
</blockquote>
<p>数据可能很多，将数据全部接收后进行压缩，称为<strong>信息瓶颈方法</strong>。可以用信息瓶颈方法来最优化地平衡准确度和复杂度。</p>
<p>信息瓶颈方法也用于分析深度学习的过程。</p>
<h2 id="最大编码率降低原理"><a href="#最大编码率降低原理" class="headerlink" title="最大编码率降低原理"></a>最大编码率降低原理</h2><p><strong>最大编码率降低原理</strong>（MCR2），这是一种信息理论度量，可以最大限度地提高整个数据集和每个类的编码率差。</p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><blockquote>
<p><a href="https://arxiv.org/abs/1703.00810" target="_blank" rel="noopener external nofollow noreferrer">Opening the Black Box of Deep Neural Networks via Information</a></p>
<p><a href="https://arxiv.org/abs/2006.08558" target="_blank" rel="noopener external nofollow noreferrer">Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222220023514.png" class="" title="信息论示例">
<p>“信息瓶颈方法”，这是我们比较少接触的；还有“最大编码率降低原理”，是从信息论或者编码理论里面出来的一些方法。</p>
<h1 id="博弈论"><a href="#博弈论" class="headerlink" title="博弈论"></a>博弈论</h1><p><a href="https://vel.life/%E5%8D%9A%E5%BC%88%E8%AE%BA/" target="_blank" rel="noopener external nofollow noreferrer">博弈论</a></p>
<h2 id="Shapley值法"><a href="#Shapley值法" class="headerlink" title="Shapley值法"></a>Shapley值法</h2><p>合作博弈中分为：</p>
<ul>
<li>功利主义：<strong>Shapley值</strong><ul>
<li>提倡最大化效益</li>
</ul>
</li>
<li>平均主义：核<ul>
<li>博弈的可行解空间构成一个核，核中任意一个分配都不会导致参与者组合脱离总合作</li>
</ul>
</li>
</ul>
<p>Shapley值衡量了一个联盟 $S$ 中参与者 $p_i$ 的<strong><font color=red>边际贡献</font></strong>。</p>
<script type="math/tex; mode=display">
\begin{equation}
\delta\left(p_{i}, S\right)=v(S)-v\left(S-\left\{p_{i}\right\}\right)
\end{equation}</script><h2 id="可解释性AI"><a href="#可解释性AI" class="headerlink" title="可解释性AI"></a>可解释性AI</h2><blockquote>
<p><a href="https://arxiv.org/abs/1705.07874" target="_blank" rel="noopener external nofollow noreferrer">A Unified Approach to Interpreting Model Predictions</a></p>
</blockquote>
<img data-src="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/image-20201222220046838.png" class="" title="博弈论示例">
<p>在可解释性AI里面有一个比较有名的方法叫Shapley值法。这个想法很简单，对一个黑箱的算法，要去看黑箱里的变量是怎么work的，以及哪些变量重要的。给它做一个可视化，可以假设这些变量之间在进行搏弈，在争夺对Response的某种payoff。在这个搏弈过程中，我们想办法把它们的贡献分配给这些变量。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>工云
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/" title="人工智能中的“新”数学">https://stellarkey.github.io/人工智能中的新数学/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag"><i class="fa fa-tag"></i> 数学</a>
              <a href="/tags/AI/" rel="tag"><i class="fa fa-tag"></i> AI</a>
          </div>

        
  <div class="post-widgets">
    <div class="wp_rating">
      <div id="wpac-rating"></div>
    </div>
  </div>


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/%E7%AC%AC%E4%BA%8C%E5%B1%8AAI%E4%B8%8E%E5%AE%89%E5%85%A8%E7%A0%94%E8%AE%A8%E4%BC%9A/" rel="prev" title="第二届AI与安全研讨会">
      <i class="fa fa-chevron-left"></i> 第二届AI与安全研讨会
    </a></div>
      <div class="post-nav-item">
    <a href="/%E8%AE%BA%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="next" title="论学习方法">
      论学习方法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#References"><span class="nav-number">1.</span> <span class="nav-text">References</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛函分析"><span class="nav-number">2.</span> <span class="nav-text">泛函分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#巴拿赫空间"><span class="nav-number">2.1.</span> <span class="nav-text">巴拿赫空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从函数到无穷维"><span class="nav-number">2.2.</span> <span class="nav-text">从函数到无穷维</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#脉冲"><span class="nav-number">2.2.1.</span> <span class="nav-text">*脉冲</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高斯核背后的映射"><span class="nav-number">2.2.2.</span> <span class="nav-text">高斯核背后的映射</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无穷宽的DNN"><span class="nav-number">2.3.</span> <span class="nav-text">无穷宽的DNN</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#群表示论与范畴论"><span class="nav-number">3.</span> <span class="nav-text">群表示论与范畴论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#关于群的研究"><span class="nav-number">3.1.</span> <span class="nav-text">关于群的研究</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从图到范畴论"><span class="nav-number">3.2.</span> <span class="nav-text">从图到范畴论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DNN中的对称性、函子"><span class="nav-number">3.3.</span> <span class="nav-text">DNN中的对称性、函子</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#微分几何"><span class="nav-number">4.</span> <span class="nav-text">微分几何</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#微分流形"><span class="nav-number">4.1.</span> <span class="nav-text">微分流形</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习的几何解释"><span class="nav-number">4.2.</span> <span class="nav-text">深度学习的几何解释</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#计算共形几何与最优传输"><span class="nav-number">5.</span> <span class="nav-text">计算共形几何与最优传输</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#最优传输散度"><span class="nav-number">5.1.</span> <span class="nav-text">最优传输散度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GAN的模式崩溃"><span class="nav-number">5.2.</span> <span class="nav-text">GAN的模式崩溃</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#代数几何"><span class="nav-number">6.</span> <span class="nav-text">代数几何</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#热带几何"><span class="nav-number">6.1.</span> <span class="nav-text">热带几何</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#计算机代数"><span class="nav-number">7.</span> <span class="nav-text">计算机代数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#向量空间、符号空间"><span class="nav-number">7.1.</span> <span class="nav-text">向量空间、符号空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多项式代数"><span class="nav-number">7.2.</span> <span class="nav-text">多项式代数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#随机矩阵"><span class="nav-number">8.</span> <span class="nav-text">随机矩阵</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#动力系统与随机分析"><span class="nav-number">9.</span> <span class="nav-text">动力系统与随机分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet"><span class="nav-number">9.1.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相平面图"><span class="nav-number">9.2.</span> <span class="nav-text">相平面图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#郎之万动力学"><span class="nav-number">9.3.</span> <span class="nav-text">郎之万动力学</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关工作"><span class="nav-number">9.4.</span> <span class="nav-text">相关工作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#统计物理与非线性科学"><span class="nav-number">10.</span> <span class="nav-text">统计物理与非线性科学</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#平均场方法"><span class="nav-number">10.1.</span> <span class="nav-text">平均场方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#混沌和分形"><span class="nav-number">10.2.</span> <span class="nav-text">混沌和分形</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一些相关工作"><span class="nav-number">10.3.</span> <span class="nav-text">一些相关工作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#信息论"><span class="nav-number">11.</span> <span class="nav-text">信息论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#信息瓶颈方法"><span class="nav-number">11.1.</span> <span class="nav-text">信息瓶颈方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最大编码率降低原理"><span class="nav-number">11.2.</span> <span class="nav-text">最大编码率降低原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关工作-1"><span class="nav-number">11.3.</span> <span class="nav-text">相关工作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#博弈论"><span class="nav-number">12.</span> <span class="nav-text">博弈论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Shapley值法"><span class="nav-number">12.1.</span> <span class="nav-text">Shapley值法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可解释性AI"><span class="nav-number">12.2.</span> <span class="nav-text">可解释性AI</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="工云"
      src="/images/stellarkey.gif">
  <p class="site-author-name" itemprop="name">工云</p>
  <div class="site-description" itemprop="description">Never stop thinking.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">63</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/stellarkey" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;stellarkey" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:velocfc@gmail.com" title="E-Mail → mailto:velocfc@gmail.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fas fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" class="cc-opacity" rel="noopener external nofollow noreferrer" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      云海之上
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.iszy.cc/" title="https:&#x2F;&#x2F;www.iszy.cc&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">随遇而安</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://asdfv1929.github.io/" title="https:&#x2F;&#x2F;asdfv1929.github.io&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">asdfv1929</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://printempw.github.io/" title="https:&#x2F;&#x2F;printempw.github.io&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">PRIN BLOG</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.cfzhao.com/" title="http:&#x2F;&#x2F;www.cfzhao.com&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">ZHAOYUWEI</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://hanherbert.github.io/" title="https:&#x2F;&#x2F;hanherbert.github.io&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">知青</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://louieworth.github.io/" title="https:&#x2F;&#x2F;louieworth.github.io&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">louieworth</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://hgen27.github.io/" title="https:&#x2F;&#x2F;hgen27.github.io&#x2F;" rel="noopener external nofollow noreferrer" target="_blank">Hgen</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-chart-line"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Vel</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">524k</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  


  
  <style>
  
  button.darkmode-toggle 
{
  z-index: 9999;
  }
  
  img, .darkmode-ignore {
    isolation: isolate;
    display: block;
  }
  </style>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/lozad.js/1.14.0/lozad.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
  <script src="/lib/darkmode-js/lib/darkmode-js.min.js"></script>


<script>
var options = {
  bottom: '32px', // default: '32px'
  right: '64px', // default: '32px'
  left: 'unset', // default: 'unset'
  time: '0.5s', // default: '0.3s'
  mixColor: '#fff', // default: '#fff'
  backgroundColor: '#fff',  // default: '#fff'
  buttonColorDark: '#100f2c',  // default: '#100f2c'
  buttonColorLight: '#fff', // default: '#fff'
  saveInCookies: true, // default: true,
  label: '🌓', // default: ''
  autoMatchOsTheme: true // default: true
}
const darkmode = new Darkmode(options);
darkmode.showWidget();
// window.onload = function(){
//   setTimeout(
//     function() {
//       document.getElementsByClassName('darkmode-toggle')[0].click();
//     },
//     550,
//   );
//   document.getElementsByClassName('darkmode-toggle')[0].click();
// }
</script>
<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  



  <script>
  if (CONFIG.page.isPost) {
    wpac_init = window.wpac_init || [];
    wpac_init.push({
      widget: 'Rating',
      id    : 27281,
      el    : 'wpac-rating',
      color : 'fc6423'
    });
    (function() {
      if ('WIDGETPACK_LOADED' in window) return;
      WIDGETPACK_LOADED = true;
      var mc = document.createElement('script');
      mc.type = 'text/javascript';
      mc.async = true;
      mc.src = '//embed.widgetpack.com/widget.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
    })();
  }
  </script>

  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://stellarkey.github.io/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E7%9A%84%E6%96%B0%E6%95%B0%E5%AD%A6/',]
      });
      });
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
